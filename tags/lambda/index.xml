<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Lambda on Docs</title><link>/tags/lambda/</link><description>Recent content in Lambda on Docs</description><generator>Hugo</generator><language>en</language><atom:link href="/tags/lambda/index.xml" rel="self" type="application/rss+xml"/><item><title>Deploying Lambda container image locally with Elastic Container Registry (ECR) using LocalStack</title><link>/tutorials/lambda-ecr-container-images/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/lambda-ecr-container-images/</guid><description>Lambda is a powerful serverless compute system that enables you to break down your application into smaller, independent functions. These functions can be deployed as individual units within the AWS ecosystem. Lambda offers seamless integration with various AWS services and supports multiple programming languages for different runtime environments. To deploy Lambda functions programmatically, you have two options: uploading a ZIP file containing your code and dependencies or packaging your code in a container image and deploying it through Elastic Container Registry (ECR).</description></item><item><title>Setting up Elastic Load Balancing (ELB) Application Load Balancers using LocalStack, deployed via the Serverless framework</title><link>/tutorials/elb-load-balancing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/elb-load-balancing/</guid><description>Elastic Load Balancer (ELB) is a service that distributes incoming application traffic across multiple targets, such as EC2 instances, containers, IP addresses, and Lambda functions. ELBs can be physical hardware or virtual software components. They accept incoming traffic and distribute it across multiple targets in one or more Availability Zones. Using ELB, you can quickly scale your load balancer to accommodate changes in traffic over time, ensuring optimal performance for your application and workloads running on the AWS infrastructure.</description></item><item><title>Creating reproducible machine learning applications using Cloud Pods for persistent state snapshots</title><link>/tutorials/reproducible-machine-learning-cloud-pods/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/reproducible-machine-learning-cloud-pods/</guid><description>LocalStack Cloud Pods enable you to create persistent state snapshots of your LocalStack instance, which can then be versioned, shared, and restored. It allows next-generation state management and team collaboration for your local cloud development environment, which you can utilize to create persistent shareable cloud sandboxes. Cloud Pods works directly with the LocalStack CLI to save, merge, and restore snapshots of your LocalStack state. You can always tear down your LocalStack instance and restore it from a snapshot at any point in time.</description></item><item><title>How To: Collaborative AWS local development with LocalStackâ€™s Cloud Pods</title><link>/tutorials/cloud-pods-collaborative-debugging/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/cloud-pods-collaborative-debugging/</guid><description>Introduction By replicating environments, teams can share the exact conditions under which a bug occurs.
For developing AWS applications locally, the tool of choice is LocalStack, which can sustain a full-blown comprehensive stack. However, when issues appear, and engineers need a second opinion from a colleague, recreating the environment from scratch can leave details slipping through the cracks. This is where Cloud Pods come in, to encapsulate the state of the LocalStack instance and allow for seamless collaboration.</description></item><item><title>Chaos Engineering: Running Experiments with Fault Injection Service</title><link>/tutorials/fault-injection-service-experiments/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/fault-injection-service-experiments/</guid><description>Introduction Fault Injection Simulator (FIS) is a service designed for conducting controlled chaos engineering tests on AWS infrastructure. Its purpose is to uncover vulnerabilities and improve system robustness. FIS offers a means to deliberately introduce failures and observe their impacts, helping developers to better equip their systems against actual outages. To read about the FIS service, refer to the dedicated FIS documentation.
Getting started This tutorial is designed for users new to the Fault Injection Simulator and assumes basic knowledge of the AWS CLI and our awslocal wrapper script.</description></item><item><title>Chaos Engineering: Route53 Failover with FIS</title><link>/tutorials/route53-failover-with-fis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/route53-failover-with-fis/</guid><description>Introduction LocalStack allows you to integrate &amp;amp; test Fault Injection Simulator (FIS) with Route53 to automatically divert users to a healthy secondary zone if the primary region fails, ensuring system availability and responsiveness. Route53&amp;rsquo;s health checks and traffic redirection enhance architecture resilience and ensure service continuity during regional outages, crucial for uninterrupted user experiences.
Note Route53 Failover with FIS is currently available as part of the LocalStack Enterprise plan. If you&amp;rsquo;d like to try it out, please contact us to request access.</description></item></channel></rss>